@article{HE2025,
title = {A Mathematical Formulation of AGI in the (C, U, V) Framework},
journal = {Engineering},
year = {2025},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2025.08.034},
url = {https://www.sciencedirect.com/science/article/pii/S2095809925005521},
author = {Di He and Cong Fang and Yisen Wang and Yujia Peng and Yizhou Wang and Song-Chun Zhu},
keywords = {Artificial general intelligence, Value alignment, Machine learning, Evolutionary learning},
abstract = {This article seeks to explore a general formulation of artificial general intelligence (AGI) under a unified framework that defines AGI agents as points in a joint (C,U,V) space. An agent is characterized by three components: ① a cognitive architecture C, which represents the modules (mathematical functions) inside the agent’s mind, as well as the connections and communication protocols between these modules, including the theory of mind (ToM); ② a set of potential functions U, which represents the skills of perception, cognition, and planning (e.g., a potential function can be a neural network trained for visual object recognition, or embodied motion planning); and ③ a set of value functions V, which includes the agent’s urges, preferences, and social affections, as well as benefits for individual agents or a group of agents. In this setting, “intelligence” is defined as a wide range of phenomena exhibited by agents when they interact with complex environments (i.e., physical intelligence) and other agents (i.e., social intelligence). Given an initial point in the (C,U,V) space, an agent can explore new V-dimensions, which in turn drives the acquisition and learning of skills by enabling the learning of new potential functions U in the environment and by updating the cognitive model. We have developed a Tong test as a benchmark and evaluation criteria: An agent that has reached the human level (C,U,V) is called a “Tong Agent.” The convergence of this process defines the limits of the agent’s evolution; we name this the “stopping problem” of Tong Agents, based on the analogy of the halting problem in a Turing machine.}
}